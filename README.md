# üìß Email Classifier MVP

**Classificador de Emails Produtivo/Improdutivo com Gera√ß√£o de Respostas Sugeridas**

Sistema completo que utiliza Machine Learning e LLMs para classificar emails automaticamente e gerar respostas contextualizadas.

---

## üéØ Funcionalidades

- ‚úÖ **Classifica√ß√£o Bin√°ria**: Produtivo (requer a√ß√£o) vs Improdutivo (dispens√°vel)
- ‚úÖ **Classifica√ß√£o com OpenAI**: GPT-4o-mini para classifica√ß√£o precisa
- ‚úÖ **Detec√ß√£o de Spam**: Identifica propaganda e emails comerciais n√£o solicitados
- ‚úÖ **Gera√ß√£o de Respostas**: Sugest√µes contextualizadas prontas para uso
- ‚úÖ **Upload de Arquivos**: Suporte para .txt e .pdf
- ‚úÖ **Hist√≥rico Local**: √öltimas an√°lises salvas no navegador
- ‚úÖ **Docker Ready**: Ambiente completo em containers
- ‚úÖ **CI/CD**: Pipelines automatizados com GitHub Actions

---

## üèóÔ∏è Arquitetura

### Stack Tecnol√≥gico

**Backend:**
- FastAPI (Python 3.13) - Framework async para APIs REST
- OpenAI API (gpt-4o-mini) - LLM para classifica√ß√£o e gera√ß√£o
- PyMuPDF - Extra√ß√£o de texto de PDFs
- NLTK - Preprocessing de texto (stopwords PT-BR)
- SQLite/PostgreSQL - Persist√™ncia de dados

**Frontend:**
- React 18 + TypeScript - SPA moderna e type-safe
- Vite - Build tool r√°pido
- TailwindCSS - Estiliza√ß√£o utility-first
- LocalStorage - Hist√≥rico de an√°lises

**Infraestrutura:**
- Docker + Docker Compose - Containeriza√ß√£o
- GitHub Actions - CI/CD

### Fluxo de Processamento

```
1. Upload/Texto ‚Üí 2. Extra√ß√£o ‚Üí 3. Preprocessing ‚Üí 4. Classifica√ß√£o OpenAI
                                                          ‚Üì
5. Gera√ß√£o de Resposta ‚Üê 6. Persist√™ncia ‚Üê 7. Retorno JSON
```

---

## üöÄ Quickstart Local

### Pr√©-requisitos

- Python 3.13+
- Node.js 20+
- Docker + Docker Compose (opcional)
- OpenAI API Key (obrigat√≥rio)

### Op√ß√£o 1: Docker Compose (Recomendado)

```bash
# 1. Clone o reposit√≥rio
git clone <repo-url>
cd email-class

# 2. Configure vari√°veis de ambiente
cp .env.example .env
# Edite .env e adicione sua OPENAI_API_KEY (obrigat√≥rio)

# 3. Inicie ambiente completo
docker-compose up --build

# 4. Acesse:
# - Frontend: http://localhost:5173
# - Backend:  http://localhost:8000
# - Docs API: http://localhost:8000/docs
```

### Op√ß√£o 2: Setup Manual

#### Backend

```bash
cd server

# Crie ambiente virtual
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Instale depend√™ncias
pip install -r requirements.txt

# Configure .env
cp ../.env.example ../.env
# Edite .env com suas credenciais

# Baixe recursos NLTK
python -c "import nltk; nltk.download('stopwords')"

# Inicie servidor
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

#### Frontend

```bash
cd client

# Instale depend√™ncias
npm install

# Configure vari√°vel de ambiente
cp .env.example .env

# Inicie dev server
npm run dev
```

### Op√ß√£o 3: Makefile (Unix/Linux/Mac)

```bash
# Setup completo
make setup

# Inicia ambiente de desenvolvimento
make dev

# Outros comandos √∫teis
make help
```

---

## üìö Uso da API

### Endpoints Principais

#### `POST /api/process`

Processa email e retorna classifica√ß√£o + resposta sugerida.

**Request (multipart/form-data):**
```bash
# Com arquivo
curl -X POST http://localhost:8000/api/process \
  -F "file=@email.txt"

# Com texto direto
curl -X POST http://localhost:8000/api/process \
  -F "text=Prezado, solicito atualiza√ß√£o urgente do chamado 12345"
```

**Response:**
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "category": "Produtivo",
  "confidence": 0.92,
  "suggested_reply": "Prezado(a), recebemos sua solicita√ß√£o...",
  "summary": "Solicita√ß√£o de atualiza√ß√£o de chamado",
  "model_used": "openai-gpt-4o-mini",
  "timestamp": "2025-11-10T15:00:00Z",
  "reason": "Email cont√©m solicita√ß√£o expl√≠cita de a√ß√£o"
}
```

#### `POST /api/feedback`

Envia feedback sobre uma an√°lise.

```bash
curl -X POST http://localhost:8000/api/feedback \
  -H "Content-Type: application/json" \
  -d '{
    "analysis_id": "550e8400-e29b-41d4-a716-446655440000",
    "rating": 5,
    "edited_reply": "Resposta customizada pelo usu√°rio",
    "comments": "Excelente classifica√ß√£o"
  }'
```

#### `GET /health`

Health check dos servi√ßos.

```bash
curl http://localhost:8000/health
```

**Documenta√ß√£o interativa:** http://localhost:8000/docs

---

## üß™ Testes

```bash
# Backend - todos os testes
cd server
pytest tests/ -v

# Com coverage
pytest tests/ --cov=app --cov-report=html

# Frontend - lint
cd client
npm run lint

# Via Makefile
make test
```

---

## üîë Configura√ß√£o de Ambiente

### Vari√°veis Obrigat√≥rias

| Vari√°vel | Descri√ß√£o | Exemplo |
|----------|-----------|---------|
| `OPENAI_API_KEY` | Chave API OpenAI (obrigat√≥rio) | `sk-...` |
| `DATABASE_URL` | URL do banco de dados | `sqlite:///./db.sqlite3` |
| `CORS_ORIGINS` | URLs permitidas (CORS) | `http://localhost:5173` |

### Vari√°veis Opcionais

| Vari√°vel | Padr√£o | Descri√ß√£o |
|----------|--------|-----------|
| `APP_ENV` | `development` | Ambiente (development/production) |
| `LLM_MODEL` | `gpt-4o-mini` | Modelo OpenAI a usar |
| `LLM_TEMPERATURE` | `0.3` | Temperatura do modelo (0-1) |
| `MAX_UPLOAD_SIZE` | `1048576` | Tamanho m√°x upload (bytes) |


---


## üìä Classifica√ß√£o com OpenAI

O sistema utiliza OpenAI GPT-4o-mini para:

- **Classifica√ß√£o**: Produtivo vs Improdutivo com precis√£o calibrada (0.60-0.99)
- **Detec√ß√£o de Spam**: Identifica propaganda, ofertas comerciais n√£o solicitadas
- **Gera√ß√£o de Respostas**: Contextualizadas e personalizadas por tipo de email
- **Custo-benef√≠cio**: ~$0.15/1M tokens input (~R$ 0,75)

### Configura√ß√£o do Modelo

Edite `server/.env`:
```env
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.3  # Classifica√ß√£o consistente
LLM_MAX_TOKENS=500
```

---

## üîí Seguran√ßa e Privacidade

### Pol√≠ticas Implementadas

‚úÖ **N√£o logar dados sens√≠veis**: PII (CPF, cart√µes) n√£o s√£o gravados em logs  
‚úÖ **Armazenamento condicional**: `full_text` s√≥ salvo em `APP_ENV=development`  
‚úÖ **Hashing**: Textos hasheados (SHA256) para deduplica√ß√£o sem expor conte√∫do  
‚úÖ **CORS configurado**: Apenas origins autorizadas  
‚úÖ **Rate limiting**: (TODO) Implementar throttling em produ√ß√£o  
‚úÖ **HTTPS obrigat√≥rio**: Em produ√ß√£o, use TLS (Render/Vercel j√° incluem)


## üìñ Documenta√ß√£o Adicional

- [PROMPTS.md](./docs/PROMPTS.md) - Prompts do LLM e varia√ß√µes para A/B testing
- [docs/architecture.md](./docs/architecture.md) - Arquitetura detalhada do sistema
- API Docs: http://localhost:8000/docs (ap√≥s iniciar backend)

---

## üõ†Ô∏è Troubleshooting

### Backend n√£o inicia

```bash
# Verifique depend√™ncias
pip list | grep fastapi

# Reinstale
pip install -r server/requirements.txt --force-reinstall

# Verifique porta ocupada
lsof -i :8000  # Unix/Mac
netstat -ano | findstr :8000  # Windows
```

### Frontend n√£o conecta ao backend

1. Verifique `VITE_API_URL` em `client/.env`
2. Confirme backend est√° rodando: `curl http://localhost:8000/health`
3. Verifique console do navegador para erros CORS


### OpenAI API falha

- Verifique cr√©ditos: https://platform.openai.com/usage
- Confirme chave em `.env`: `echo $OPENAI_API_KEY`
- Sistema retornar√° erro HTTP 500 se OpenAI indispon√≠vel

---

## üìù Roadmap

### v1.0 (Atual - MVP)
- [x] Classifica√ß√£o bin√°ria
- [x] Gera√ß√£o de respostas
- [x] Upload PDF/TXT
- [x] Hist√≥rico local
- [x] Docker + CI/CD

---

## üìÑ Licen√ßa

MIT License - veja [LICENSE](./LICENSE)

---

## üë• Autores

Desenvolvido como MVP para demonstra√ß√£o de IA aplicada em triagem de emails.

**Justificativas T√©cnicas:**

- **FastAPI**: Escolhido por performance async, type hints, e docs autom√°ticas
- **OpenAI GPT-4o-mini**: Melhor custo-benef√≠cio (~10x mais barato que GPT-4)
- **SQLite ‚Üí Postgres**: F√°cil migra√ß√£o via SQLAlchemy/DATABASE_URL
- **Tailwind**: Produtividade e bundle size otimizado
- **Vercel + Render**: Planos gratuitos generosos para MVPs

---

## üÜò Suporte

- Issues: [GitHub Issues](https://github.com/luizfsjunior/email-class/issues)
- Email: luizfsjunior.2002@gmail.com
- Docs: http://localhost:8000/docs

