"""
AI Client abstraction - Interface para LLMs (OpenAI, HuggingFace, etc)
Permite trocar provider facilmente e implementa fallback strategy
"""
import json
import logging
from typing import Dict, Optional, Literal
from openai import AsyncOpenAI
from app.core.settings import get_settings

logger = logging.getLogger(__name__)

CategoryType = Literal["Produtivo", "Improdutivo"]


class AIClient:
    """Cliente abstrato para chamadas LLM com fallback"""
    
    def __init__(self):
        self.settings = get_settings()
        
        if not self.settings.OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY n√£o configurada. Configure a chave em server/.env")
        
        self.client = AsyncOpenAI(api_key=self.settings.OPENAI_API_KEY)
        logger.info("OpenAI client inicializado")
    
    async def classify_email(self, text: str) -> Dict:
        """
        Classifica email usando LLM
        
        Returns:
            Dict com: category, confidence, reason
        """
        prompt = self._build_classification_prompt(text)
        
        try:
            response = await self.client.chat.completions.create(
                model=self.settings.LLM_MODEL,
                messages=[
                    {
                        "role": "system", 
                        "content": "Voc√™ √© um classificador especialista. CALIBRE a confian√ßa baseada em: clareza do email (0.90-0.99 se muito claro, 0.70-0.85 se amb√≠guo, 0.60-0.70 se confuso), completude de informa√ß√µes (mais dados = maior confian√ßa), e certeza da categoria. Detecte spam por: links, linguagem marketing ('ganhe', 'promo√ß√£o', '50% OFF'), urg√™ncia artificial. Seja preciso na confian√ßa - n√£o use sempre valores altos. Responda em JSON v√°lido."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=self.settings.LLM_TEMPERATURE,
                max_tokens=self.settings.LLM_MAX_TOKENS,
                response_format={"type": "json_object"}
            )
            
            content = response.choices[0].message.content
            
            # DEBUG: Log da resposta RAW da OpenAI
            logger.info("=" * 60)
            logger.info("ü§ñ RESPOSTA RAW DA OPENAI:")
            logger.info(f"Texto analisado (primeiros 100 chars): {text[:100]}")
            logger.info(f"Resposta JSON: {content}")
            logger.info("=" * 60)
            
            result = json.loads(content)
            
            # Valida campos obrigat√≥rios
            if "category" not in result or "confidence" not in result:
                raise ValueError("Resposta LLM sem campos obrigat√≥rios")
            
            # Normaliza categoria
            result["category"] = self._normalize_category(result["category"])
            
            return result
            
        except Exception as e:
            logger.error(f"Erro ao chamar OpenAI: {str(e)}")
            raise
    
    async def generate_reply(self, category: CategoryType, summary: str, original_text: str) -> Dict:
        """
        Gera resposta sugerida usando LLM
        
        Returns:
            Dict com: reply, tone, max_words
        """
        prompt = self._build_reply_prompt(category, summary, original_text)
        
        try:
            response = await self.client.chat.completions.create(
                model=self.settings.LLM_MODEL,
                messages=[
                    {"role": "system", "content": "Voc√™ √© um atendente humano experiente que escreve respostas personalizadas, emp√°ticas e contextualizadas. Nunca use templates gen√©ricos."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,  # Temperatura mais alta para respostas criativas
                max_tokens=self.settings.LLM_MAX_TOKENS,
                response_format={"type": "json_object"}
            )
            
            content = response.choices[0].message.content
            result = json.loads(content)
            
            if "reply" not in result:
                raise ValueError("Resposta LLM sem campo 'reply'")
            
            return result
            
        except Exception as e:
            logger.error(f"Erro ao gerar resposta: {str(e)}")
            raise
    
    def _build_classification_prompt(self, text: str) -> str:
        """Constr√≥i prompt de classifica√ß√£o"""
        return f"""Voc√™ √© um classificador especialista em triagem de emails corporativos.

üìã CLASSIFICA√á√ÉO E PRECIS√ÉO:

A "precis√£o" (confidence) reflete qu√£o CERTO o modelo est√° da classifica√ß√£o, baseado na clareza e completude da informa√ß√£o.

**CATEGORIA IMPRODUTIVO** (n√£o requer a√ß√£o):
‚Ä¢ Agradecimentos puros ‚Üí Precis√£o: 0.95-0.99
‚Ä¢ Felicita√ß√µes/Sauda√ß√µes ‚Üí Precis√£o: 0.95-0.99
‚Ä¢ Confirma√ß√µes simples ‚Üí Precis√£o: 0.92-0.97
‚Ä¢ Problemas J√Å resolvidos ‚Üí Precis√£o: 0.90-0.95
‚Ä¢ Elogios ao atendimento ‚Üí Precis√£o: 0.93-0.98
‚Ä¢ SPAM/Propaganda ‚Üí Precis√£o: 0.88-0.95 (identificadores: links suspeitos, promo√ß√µes gen√©ricas, "clique aqui", "ganhe j√°", linguagem de marketing agressivo, ofertas n√£o solicitadas)
‚Ä¢ Avisos informativos ‚Üí Precis√£o: 0.85-0.92

**CATEGORIA PRODUTIVO** (requer a√ß√£o):
‚Ä¢ Solicita√ß√£o espec√≠fica com dados ‚Üí Precis√£o: 0.92-0.98
‚Ä¢ Problema atual n√£o resolvido ‚Üí Precis√£o: 0.88-0.95
‚Ä¢ D√∫vida que exige resposta ‚Üí Precis√£o: 0.85-0.93
‚Ä¢ Reclama√ß√£o que demanda a√ß√£o ‚Üí Precis√£o: 0.87-0.94
‚Ä¢ Urg√™ncia expl√≠cita ‚Üí Precis√£o: 0.90-0.96

**CASOS AMB√çGUOS** (reduzir precis√£o):
‚Ä¢ Email misto (agradecimento + nova d√∫vida) ‚Üí Analise qual predomina, precis√£o: 0.70-0.85
‚Ä¢ Contexto incompleto ‚Üí Precis√£o: 0.65-0.80
‚Ä¢ Linguagem pouco clara ‚Üí Precis√£o: 0.60-0.75

---

**EXEMPLOS COM PRECIS√ÉO CALIBRADA:**

Email: "Obrigado!"
{{"category": "Improdutivo", "confidence": 0.98, "reason": "Agradecimento puro sem contexto adicional ou demanda. Precis√£o alta por clareza total."}}

Email: "PROMO√á√ÉO! Ganhe 50% OFF. Clique aqui: www.exemplo.com"
{{"category": "Improdutivo", "confidence": 0.92, "reason": "Spam/propaganda com linguagem de marketing agressivo e link comercial. Precis√£o alta."}}

Email: "Feliz Natal a todos da equipe!"
{{"category": "Improdutivo", "confidence": 0.99, "reason": "Felicita√ß√£o sazonal sem qualquer solicita√ß√£o. Classifica√ß√£o √≥bvia, precis√£o m√°xima."}}

Email: "Problema resolvido, funcionou!"
{{"category": "Improdutivo", "confidence": 0.94, "reason": "Confirma√ß√£o de resolu√ß√£o sem nova demanda. Alta precis√£o pela clareza."}}

Email: "Preciso atualizar meu endere√ßo para Rua das Flores, 123, S√£o Paulo"
{{"category": "Produtivo", "confidence": 0.95, "reason": "Solicita√ß√£o espec√≠fica de atualiza√ß√£o cadastral com dados completos. Precis√£o alta."}}

Email: "Quando fica pronto?"
{{"category": "Produtivo", "confidence": 0.78, "reason": "D√∫vida v√°lida mas contexto incompleto reduz precis√£o."}}

Email: "Obrigado pela ajuda. Mas tenho outra d√∫vida sobre taxas"
{{"category": "Produtivo", "confidence": 0.83, "reason": "Apesar do agradecimento, h√° nova d√∫vida que demanda resposta. Precis√£o moderada-alta."}}

Email: "Descubra como GANHAR DINHEIRO r√°pido! Acesse agora"
{{"category": "Improdutivo", "confidence": 0.95, "reason": "Spam cl√°ssico com linguagem sensacionalista e promessa financeira gen√©rica. Precis√£o alta."}}

---

üéØ ANALISE ESTE EMAIL:

EMAIL:
\"\"\"
{text[:2000]}
\"\"\"

**INSTRU√á√ïES:**
1. Identifique a inten√ß√£o PRINCIPAL do email
2. Avalie clareza do contexto e dados fornecidos
3. Detecte indicadores de spam (links, linguagem marketing, "ganhe", "promo√ß√£o", ofertas n√£o solicitadas)
4. Calibre precis√£o baseada em CERTEZA da classifica√ß√£o (n√£o em import√¢ncia)
5. Seja RIGOROSO: se h√° agradecimento/felicita√ß√£o/confirma√ß√£o SEM nova demanda ‚Üí Improdutivo

Responda APENAS com JSON:
{{"category": "Produtivo" | "Improdutivo", "confidence": 0.60-0.99, "reason": "explique em 25-50 palavras a decis√£o E por que a precis√£o est√° nesse n√≠vel"}}"""
    
    def _build_reply_prompt(self, category: CategoryType, summary: str, original_text: str) -> str:
        """Constr√≥i prompt de gera√ß√£o de resposta"""
        
        # Detecta spam no texto original
        spam_indicators = [
            "promo√ß√£o", "ganhe", "desconto", "clique aqui", "oferta", "gr√°tis", "gratuito",
            "www.", "http", "click", "acesse j√°", "imperd√≠vel", "limitado", "exclusivo",
            "parab√©ns voc√™ ganhou", "foi selecionado", "pr√™mio", "sorteio"
        ]
        is_spam = any(indicator in original_text.lower() for indicator in spam_indicators)
        
        if is_spam:
            instruction = """Este email √© SPAM/Propaganda comercial n√£o solicitado. Gere uma resposta CURTA, FIRME e PROFISSIONAL que:
1. N√ÉO agrade√ßa nem demonstre interesse
2. Informe que mensagens comerciais n√£o s√£o aceitas neste canal
3. Seja educada mas assertiva
4. Seja breve (1-2 linhas)

EXEMPLOS DE RESPOSTAS ADEQUADAS:
‚Ä¢ "Esta mensagem foi identificada como spam. N√£o aceitamos promo√ß√µes comerciais neste canal de atendimento."
‚Ä¢ "Mensagens promocionais n√£o solicitadas ser√£o bloqueadas. Este n√£o √© o canal adequado para ofertas comerciais."
‚Ä¢ "Email marcado como spam. Para contato comercial, utilize nossos canais oficiais de marketing."

N√ÉO use: agradecimentos, "obrigado por entrar em contato", "ficamos felizes", ou qualquer linguagem que incentive mais mensagens."""
        elif category == "Produtivo":
            instruction = """Gere uma resposta personalizada e PROATIVA que:
1. Reconhe√ßa ESPECIFICAMENTE o assunto mencionado (use detalhes do email)
2. Se houver n√∫mero de protocolo/chamado/pedido, MENCIONE-O
3. Indique pr√≥ximos passos CONCRETOS (ex: "vamos verificar no sistema", "nossa equipe analisar√°")
4. Se poss√≠vel, d√™ prazo aproximado (24-48h √∫teis)
5. Use tom emp√°tico mas profissional
6. Personalize com base no contexto (urg√™ncia, tipo de problema)

Evite: "recebemos sua solicita√ß√£o" (muito gen√©rico). Seja ESPEC√çFICO ao problema."""
        else:
            instruction = """Gere uma resposta CALOROSA e BREVE que:
1. Agrade√ßa de forma PERSONALIZADA ao contexto espec√≠fico
2. Reconhe√ßa o sentimento/a√ß√£o expressa (agradecimento, felicita√ß√£o, etc)
3. Reforce disponibilidade de forma GENU√çNA
4. Seja breve (2-3 linhas no m√°ximo)
5. Adapte o tom ao email recebido

Evite: f√≥rmulas prontas gen√©ricas. Cada resposta deve parecer √∫nica."""
        
        return f"""Voc√™ √© um atendente experiente de institui√ß√£o financeira que escreve respostas humanizadas.

Email recebido:
\"\"\"
{original_text[:800]}
\"\"\"

Categoria: {category}
Resumo: {summary}
Spam detectado: {is_spam}

{instruction}

Responda em JSON:
{{"reply":"texto da resposta (2-5 linhas, m√°ximo 80 palavras)", "tone":"profissional|emp√°tico|cordial|firme", "max_words":80}}"""
    
    def _normalize_category(self, category: str) -> CategoryType:
        """Normaliza categoria para valores aceitos"""
        cat_lower = category.lower().strip()
        # IMPORTANTE: Verificar "improdutivo" ANTES de "produtivo" 
        # porque "improdutivo" cont√©m "produtivo"!
        if "improdutivo" in cat_lower:
            return "Improdutivo"
        elif "produtivo" in cat_lower or "productive" in cat_lower:
            return "Produtivo"
        return "Improdutivo"  # Default seguro


# Singleton instance
_ai_client: Optional[AIClient] = None

def get_ai_client() -> AIClient:
    """Retorna inst√¢ncia singleton do AI client"""
    global _ai_client
    if _ai_client is None:
        _ai_client = AIClient()
    return _ai_client
