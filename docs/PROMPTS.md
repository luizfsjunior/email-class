# ğŸ¤– Prompts para LLM - Email Classifier

Este documento contÃ©m os prompts utilizados pelo sistema para classificaÃ§Ã£o de emails e geraÃ§Ã£o de respostas, incluindo variaÃ§Ãµes para A/B testing.

---

## ğŸ“‹ Ãndice

1. [Prompt de ClassificaÃ§Ã£o](#prompt-de-classificaÃ§Ã£o)
2. [Prompt de GeraÃ§Ã£o de Resposta](#prompt-de-geraÃ§Ã£o-de-resposta)
3. [VariaÃ§Ãµes para A/B Testing](#variaÃ§Ãµes-para-ab-testing)
4. [Boas PrÃ¡ticas](#boas-prÃ¡ticas)

---

## ğŸ¯ Prompt de ClassificaÃ§Ã£o

### VersÃ£o Principal (ProduÃ§Ã£o)

**LocalizaÃ§Ã£o:** `server/app/services/ai_client.py` â†’ `_build_classification_prompt()`

**InstruÃ§Ãµes do System Message:**
```
VocÃª Ã© um classificador especialista. CALIBRE a confianÃ§a baseada em: clareza do email (0.90-0.99 se muito claro, 0.70-0.85 se ambÃ­guo, 0.60-0.70 se confuso), completude de informaÃ§Ãµes (mais dados = maior confianÃ§a), e certeza da categoria. Detecte spam por: links, linguagem marketing ('ganhe', 'promoÃ§Ã£o', '50% OFF'), urgÃªncia artificial. Seja preciso na confianÃ§a - nÃ£o use sempre valores altos. Responda em JSON vÃ¡lido.
```

**User Prompt (resumido):**
```
VocÃª Ã© um classificador especialista em triagem de emails corporativos.

ğŸ“‹ CLASSIFICAÃ‡ÃƒO E PRECISÃƒO:

A "precisÃ£o" (confidence) reflete quÃ£o CERTO o modelo estÃ¡ da classificaÃ§Ã£o, baseado na clareza e completude da informaÃ§Ã£o.

**CATEGORIA IMPRODUTIVO** (nÃ£o requer aÃ§Ã£o):
â€¢ Agradecimentos puros â†’ PrecisÃ£o: 0.95-0.99
â€¢ FelicitaÃ§Ãµes/SaudaÃ§Ãµes â†’ PrecisÃ£o: 0.95-0.99
â€¢ ConfirmaÃ§Ãµes simples â†’ PrecisÃ£o: 0.92-0.97
â€¢ Problemas JÃ resolvidos â†’ PrecisÃ£o: 0.90-0.95
â€¢ Elogios ao atendimento â†’ PrecisÃ£o: 0.93-0.98
â€¢ SPAM/Propaganda â†’ PrecisÃ£o: 0.88-0.95 (links suspeitos, "clique aqui", "ganhe jÃ¡", linguagem marketing)
â€¢ Avisos informativos â†’ PrecisÃ£o: 0.85-0.92

**CATEGORIA PRODUTIVO** (requer aÃ§Ã£o):
â€¢ SolicitaÃ§Ã£o especÃ­fica com dados â†’ PrecisÃ£o: 0.92-0.98
â€¢ Problema atual nÃ£o resolvido â†’ PrecisÃ£o: 0.88-0.95
â€¢ DÃºvida que exige resposta â†’ PrecisÃ£o: 0.85-0.93
â€¢ ReclamaÃ§Ã£o que demanda aÃ§Ã£o â†’ PrecisÃ£o: 0.87-0.94
â€¢ UrgÃªncia explÃ­cita â†’ PrecisÃ£o: 0.90-0.96

**CASOS AMBÃGUOS** (reduzir precisÃ£o):
â€¢ Email misto â†’ PrecisÃ£o: 0.70-0.85
â€¢ Contexto incompleto â†’ PrecisÃ£o: 0.65-0.80
â€¢ Linguagem pouco clara â†’ PrecisÃ£o: 0.60-0.75

[8 exemplos detalhados com precisÃ£o calibrada]

EMAIL:
{{EMAIL_TEXT}}

Responda APENAS com JSON:
{"category": "Produtivo" | "Improdutivo", "confidence": 0.60-0.99, "reason": "explique em 25-50 palavras a decisÃ£o E por que a precisÃ£o estÃ¡ nesse nÃ­vel"}
```

**ConfiguraÃ§Ã£o:**
- Model: `gpt-4o-mini`
- Temperature: `0.3` (baixa criatividade, mais consistÃªncia)
- Max Tokens: `500`
- Response Format: `json_object` (forÃ§a JSON vÃ¡lido)

**Exemplo de Response:**
```json
{
  "category": "Produtivo",
  "confidence": 0.92,
  "reason": "Email solicita atualizaÃ§Ã£o de chamado com prazo definido. Alta precisÃ£o pela clareza da demanda e dados fornecidos."
}
```

**Indicadores de Spam Detectados:**
- Links suspeitos (www., http)
- Linguagem marketing: "promoÃ§Ã£o", "ganhe", "desconto", "clique aqui", "oferta", "grÃ¡tis"
- UrgÃªncia artificial: "imperdÃ­vel", "limitado", "exclusivo", "acesse jÃ¡"
- Fraude: "parabÃ©ns vocÃª ganhou", "foi selecionado", "prÃªmio", "sorteio"

---

## âœ‰ï¸ Prompt de GeraÃ§Ã£o de Resposta

### VersÃ£o Principal (ProduÃ§Ã£o)

**LocalizaÃ§Ã£o:** `server/app/services/ai_client.py` â†’ `_build_reply_prompt()`

**InstruÃ§Ãµes do System Message:**
```
VocÃª Ã© um atendente humano experiente que escreve respostas personalizadas, empÃ¡ticas e contextualizadas. Nunca use templates genÃ©ricos.
```

**User Prompt (estrutura):**
```
VocÃª Ã© um atendente experiente de instituiÃ§Ã£o financeira que escreve respostas humanizadas.

Email recebido:
{{ORIGINAL_TEXT}}

Categoria: {{CATEGORY}}
Resumo: {{SUMMARY}}
Spam detectado: {{IS_SPAM}}

[InstruÃ§Ãµes condicionais baseadas em categoria/spam]

Responda em JSON:
{"reply":"texto da resposta (2-5 linhas, mÃ¡ximo 80 palavras)", "tone":"profissional|empÃ¡tico|cordial|firme", "max_words":80}
```

**InstruÃ§Ãµes Condicionais:**

1. **Se SPAM:**
```
Gere uma resposta CURTA, FIRME e PROFISSIONAL que:
- NÃƒO agradeÃ§a nem demonstre interesse
- Informe que mensagens comerciais nÃ£o sÃ£o aceitas neste canal
- Seja educada mas assertiva
- Seja breve (1-2 linhas)

Exemplo: "Esta mensagem foi identificada como spam. NÃ£o aceitamos promoÃ§Ãµes comerciais neste canal de atendimento."
```

2. **Se PRODUTIVO:**
```
Gere uma resposta personalizada e PROATIVA que:
- ReconheÃ§a ESPECIFICAMENTE o assunto mencionado (use detalhes do email)
- Se houver nÃºmero de protocolo/chamado/pedido, MENCIONE-O
- Indique prÃ³ximos passos CONCRETOS (ex: "vamos verificar no sistema")
- Se possÃ­vel, dÃª prazo aproximado (24-48h Ãºteis)
- Use tom empÃ¡tico mas profissional
- Personalize com base no contexto (urgÃªncia, tipo de problema)

Evite: "recebemos sua solicitaÃ§Ã£o" (muito genÃ©rico). Seja ESPECÃFICO.
```

3. **Se IMPRODUTIVO:**
```
Gere uma resposta CALOROSA e BREVE que:
- AgradeÃ§a de forma PERSONALIZADA ao contexto especÃ­fico
- ReconheÃ§a o sentimento/aÃ§Ã£o expressa (agradecimento, felicitaÃ§Ã£o, etc)
- Reforce disponibilidade de forma GENUÃNA
- Seja breve (2-3 linhas no mÃ¡ximo)
- Adapte o tom ao email recebido

Evite: fÃ³rmulas prontas genÃ©icas. Cada resposta deve parecer Ãºnica.
```

**ConfiguraÃ§Ã£o:**
- Model: `gpt-4o-mini`
- Temperature: `0.7` (maior criatividade para respostas personalizadas)
- Max Tokens: `500`

**Exemplo de Response:**
```json
{
  "reply": "OlÃ¡! Verificamos sua solicitaÃ§Ã£o sobre o chamado #12345. Nossa equipe tÃ©cnica jÃ¡ iniciou a anÃ¡lise e vocÃª receberÃ¡ uma atualizaÃ§Ã£o detalhada em atÃ© 24 horas Ãºteis. Agradecemos a paciÃªncia!",
  "tone": "empÃ¡tico",
  "max_words": 35
}
```

---

## ğŸ§ª Propostas para A/B Testing Futuro

O sistema atual usa prompts otimizados (documentados acima). Abaixo estÃ£o **propostas experimentais** para testes futuros.

### EstratÃ©gias de Teste

#### Teste 1: Ajuste de PrecisÃ£o

| VersÃ£o | ConfiguraÃ§Ã£o | HipÃ³tese |
|--------|-------------|----------|
| A (atual) | Escala 0.60-0.99 com faixas | CalibraÃ§Ã£o precisa |
| B | Escala 0.70-1.0 (mais confiante) | UsuÃ¡rios preferem alta confianÃ§a |
| C | Escala 0.50-0.95 (mais ampla) | Melhor diferenciaÃ§Ã£o de casos |

**MÃ©trica:** CorrelaÃ§Ã£o entre confianÃ§a e feedback humano

---

#### Teste 2: Quantidade de Exemplos

| VersÃ£o | Estrutura | HipÃ³tese |
|--------|-----------|----------|
| A (atual) | 8 exemplos detalhados | EquilÃ­brio atual |
| B | 3-4 exemplos (simplificado) | Menor latÃªncia, mesma acurÃ¡cia |
| C | 12+ exemplos (expandido) | Maior acurÃ¡cia em casos edge |

**MÃ©trica:** AcurÃ¡cia vs latÃªncia vs custo

---

#### Teste 3: Tratamento de Spam

| VersÃ£o | Abordagem | Trade-off |
|--------|----------|-----------|
| A (atual) | 15 indicadores, resposta firme | EquilÃ­brio atual |
| B | 5 indicadores (conservador) | Menos falsos positivos |
| C | 25+ indicadores (agressivo) | Maior recall, possÃ­veis falsos positivos |

**MÃ©trica:** Precision vs Recall de detecÃ§Ã£o de spam

---

**MÃ©trica:** Precision vs Recall de detecÃ§Ã£o de spam

---

#### Teste 4: Temperature de Respostas

| VersÃ£o | Temperature | HipÃ³tese |
|--------|-------------|----------|
| A (atual) | 0.7 | EquilÃ­brio criatividade/consistÃªncia |
| B | 0.5 | Respostas mais consistentes |
| C | 0.9 | MÃ¡xima personalizaÃ§Ã£o |

**MÃ©trica:** Taxa de ediÃ§Ã£o + rating de qualidade

---

#### Teste 5: Tamanho de Contexto

| VersÃ£o | Input Truncado | Trade-off |
|--------|---------------|-----------|
| A (atual) | 2000 chars | EquilÃ­brio atual |
| B | 1000 chars | Menor custo, mais rÃ¡pido |
| C | 4000 chars | Contexto completo, mais caro |

**MÃ©trica:** Custo vs acurÃ¡cia vs latÃªncia

---

## ğŸ“Š Monitoramento e OtimizaÃ§Ã£o

### MÃ©tricas a Acompanhar

1. **AcurÃ¡cia de ClassificaÃ§Ã£o**
   - Target: >90%
   - MediÃ§Ã£o: Comparar com labels humanos

2. **Qualidade de Resposta**
   - Rating mÃ©dio (1-5 estrelas)
   - Taxa de ediÃ§Ã£o (% respostas editadas)
   - NPS (feedback qualitativo)

3. **Performance**
   - LatÃªncia mÃ©dia (target: <2s)
   - Taxa de erro OpenAI
   - Custo por classificaÃ§Ã£o
   - Taxa de detecÃ§Ã£o de spam (precision/recall)

---

## âœ… Boas PrÃ¡ticas

### Prompt Engineering

1. **Seja EspecÃ­fico**: Defina exatamente o formato de output
2. **Use JSON Schema**: Force estrutura com `response_format`
3. **Limite Output**: Defina `max_tokens` para evitar respostas longas
4. **Temperature Calibrada**: Use 0.3 para classificaÃ§Ã£o (consistÃªncia), 0.7 para respostas (criatividade)
5. **System Message**: Sempre defina contexto geral e comportamento esperado
6. **Sanitize Input**: Limite tamanho de input (evite custos excessivos)
7. **CalibraÃ§Ã£o de ConfianÃ§a**: Use escalas baseadas em clareza (0.60-0.99), nÃ£o em importÃ¢ncia
8. **DetecÃ§Ã£o de Spam**: Liste indicadores especÃ­ficos no prompt para identificaÃ§Ã£o consistente

### SeguranÃ§a

1. **NÃ£o exponha dados sensÃ­veis**: Remova PII antes de enviar ao LLM
2. **Rate Limiting**: Implemente throttling
3. **Timeout**: Defina timeout de 10s max
4. **Log de Prompts**: Salve prompts para auditoria (sem dados sensÃ­veis)

### OtimizaÃ§Ã£o de Custos

1. **Cache de Respostas**: Mesma pergunta = mesma resposta (hash do texto)
2. **Batch Processing**: Agrupe mÃºltiplas classificaÃ§Ãµes quando possÃ­vel
3. **Modelo Adequado**: GPT-4o-mini (~$0.15/1M tokens) vs GPT-4 (~$30/1M tokens) - 200x diferenÃ§a
4. **Truncate Input**: Primeiros 2000 chars geralmente suficientes
5. **Monitor Usage**: Alerta quando ultrapassar budget
6. **Temperature Apropriada**: 0.3 para classificaÃ§Ã£o economiza tokens vs 0.7+

---

## ğŸ”„ Versionamento de Prompts

### Como Versionar

1. Cada mudanÃ§a significativa = nova versÃ£o
2. Documente em git commit
3. Salve mÃ©tricas de cada versÃ£o
4. A/B test antes de rollout completo

### Template de Changelog

```markdown
## v1.2 - 2025-11-10

### ClassificaÃ§Ã£o
- Adicionada calibraÃ§Ã£o de precisÃ£o (0.60-0.99 baseado em clareza)
- Implementada detecÃ§Ã£o de spam com 15+ indicadores
- System message expandido com instruÃ§Ãµes de calibraÃ§Ã£o
- Aumentado confidence threshold de 0.7 para 0.8

### GeraÃ§Ã£o de Respostas
- Temperature alterada de 0.3 para 0.7 (respostas mais personalizadas)
- Adicionado tratamento especÃ­fico para spam (tom firme)
- InstruÃ§Ãµes condicionais por categoria (Produtivo/Improdutivo/Spam)
- System message focado em humanizaÃ§Ã£o

### Resultados
- PrecisÃ£o: 87% â†’ 91%
- LatÃªncia: 1.8s â†’ 1.5s
- Custo: $0.002 â†’ $0.0015 por classificaÃ§Ã£o
- Spam detection: 0% â†’ 94% recall
```

---


## ğŸ“š ReferÃªncias

- [OpenAI Best Practices](https://platform.openai.com/docs/guides/prompt-engineering)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [LangChain Prompt Templates](https://python.langchain.com/docs/modules/model_io/prompts/)

---

**VersÃ£o do sistema:** 1.0.0  
**Modelo primÃ¡rio:** gpt-4o-mini
